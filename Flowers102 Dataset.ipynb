{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aNHkUv5-zv8F"
      },
      "source": [
        "### **Libraries**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "9CJx4x1pzxtc"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision.datasets import ImageFolder\n",
        "from torch.utils.data import DataLoader\n",
        "import tensorflow_datasets as tfds\n",
        "from sklearn.metrics import f1_score\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import torchvision.models as models\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NjiLMc300PrZ",
        "outputId": "1e9e08a1-7b2e-4789-8521-30729fbe3b96"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device: cuda\n"
          ]
        }
      ],
      "source": [
        "# Check GPU availability\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BsU6DNdy0bAM"
      },
      "source": [
        "### **Dataset**\n",
        "\n",
        "The **Flowers-102** dataset consists of of 8,189 color images, each of size 224x224 pixels, divided into 102 classes with 40 - 258 images per class..\n",
        "\n",
        "In this case, images are resized to match the required input size of some models as most of them require a 224x224 image size as they were programmed on ImageNet."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a8iGnlfU0SGN",
        "outputId": "188ff0b5-f537-4f5f-c75c-4d02f640e27b"
      },
      "outputs": [],
      "source": [
        "# Size tranformation\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),  # Resize to match models' expected input size\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]) # ImageNet mean values\n",
        "])\n",
        "\n",
        "# Size tranformation for InceptionV3\n",
        "transform_inception = transforms.Compose([\n",
        "    transforms.Resize((299, 299)),  # Resize to 299x299 pixels for InceptionV3\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "])\n",
        "\n",
        "# Load the Flower-102 dataset\n",
        "(ds_train, ds_test), ds_info = tfds.load(\n",
        "    'oxford_flowers102',\n",
        "    split=['train', 'test'],\n",
        "    shuffle_files=True,\n",
        "    as_supervised=True,\n",
        "    with_info=True,\n",
        ")\n",
        "\n",
        "# Convert TFDS datasets to ImageFolder-like structure for PyTorch\n",
        "def tfds_to_imagefolder(ds, transform):\n",
        "    images, labels = [], []\n",
        "    for image, label in tfds.as_numpy(ds):\n",
        "        image = transform(transforms.ToPILImage()(image))\n",
        "        images.append(image)\n",
        "        labels.append(label)\n",
        "    dataset = list(zip(images, labels))\n",
        "    return dataset\n",
        "\n",
        "trainset = tfds_to_imagefolder(ds_train, transform)\n",
        "testset = tfds_to_imagefolder(ds_test, transform)\n",
        "trainset_inception = tfds_to_imagefolder(ds_train, transform_inception)\n",
        "testset_inception = tfds_to_imagefolder(ds_test, transform_inception)\n",
        "\n",
        "# Create DataLoaders\n",
        "trainloader = DataLoader(trainset, batch_size=32, shuffle=True, num_workers=2)\n",
        "testloader = DataLoader(testset, batch_size=32, shuffle=False, num_workers=2)\n",
        "trainloader_inception = DataLoader(trainset_inception, batch_size=32, shuffle=True, num_workers=2)\n",
        "testloader_inception = DataLoader(testset_inception, batch_size=32, shuffle=False, num_workers=2)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F1C7_Hb10seV"
      },
      "source": [
        "The CNN architectures that will be considered are the following:\n",
        "\n",
        "\n",
        "- **AlexNet:** Original architecture\n",
        "- **ResNet:** ResNet-50\n",
        "- **VGGNet:** VGG-16\n",
        "- **GoogleNet:** Inception v3\n",
        "- **EfficientNet:** EfficientNet-B1, EfficientNet-B3 EfficientNet-B5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mrgUd4ZB1OJ5",
        "outputId": "e23b4017-f02d-4244-b67c-88507ded051b"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\aleca\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "c:\\Users\\aleca\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=AlexNet_Weights.IMAGENET1K_V1`. You can also use `weights=AlexNet_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "c:\\Users\\aleca\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "c:\\Users\\aleca\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "c:\\Users\\aleca\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=Inception_V3_Weights.IMAGENET1K_V1`. You can also use `weights=Inception_V3_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "c:\\Users\\aleca\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=EfficientNet_B1_Weights.IMAGENET1K_V1`. You can also use `weights=EfficientNet_B1_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "c:\\Users\\aleca\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=EfficientNet_B3_Weights.IMAGENET1K_V1`. You can also use `weights=EfficientNet_B3_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "c:\\Users\\aleca\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=EfficientNet_B5_Weights.IMAGENET1K_V1`. You can also use `weights=EfficientNet_B5_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        }
      ],
      "source": [
        "# Define models\n",
        "models = {\n",
        "    'AlexNet': torchvision.models.alexnet(pretrained=True),\n",
        "    'ResNet50': torchvision.models.resnet50(pretrained=True),\n",
        "    'VGG16': torchvision.models.vgg16(pretrained=True),\n",
        "    'InceptionV3': torchvision.models.inception_v3(pretrained=True, aux_logits=True),\n",
        "    'EfficientNet-B1': torchvision.models.efficientnet_b1(pretrained=True),\n",
        "    'EfficientNet-B3': torchvision.models.efficientnet_b3(pretrained=True),\n",
        "    'EfficientNet-B5': torchvision.models.efficientnet_b5(pretrained=True)\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The following code ensures that each model is adapted to the Flower-102 dataset by replacing the final layer of the model. For models like AlexNet, VGG, and EfficientNet, this modification is made to the classifier's last layer, while for Inception and other models, it's made to the last fully connected layer "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "mKU72Ur81ifC"
      },
      "outputs": [],
      "source": [
        "# Modify the final layer to match CIFAR-100 classes\n",
        "for name, model in models.items():\n",
        "    if 'EfficientNet' in name:\n",
        "        num_ftrs = model.classifier[-1].in_features\n",
        "        model.classifier[-1] = nn.Linear(num_ftrs, 102)\n",
        "    elif 'Inception' in name:\n",
        "        num_ftrs = model.fc.in_features\n",
        "        model.fc = nn.Linear(num_ftrs, 102)\n",
        "    elif 'AlexNet' in name or 'VGG' in name:\n",
        "        num_ftrs = model.classifier[-1].in_features\n",
        "        model.classifier[-1] = nn.Linear(num_ftrs, 102)\n",
        "    else:\n",
        "        num_ftrs = model.fc.in_features\n",
        "        model.fc = nn.Linear(num_ftrs, 102)\n",
        "    models[name] = model.to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This part initializes the loss function used for training the models. Cross-entropy loss measures how well a model's predicted probability distribution matches the actual distribution of the labels.\n",
        "\n",
        "The mathematical definition of the cross-entropy loss for a dataset is defined as:\n",
        "\n",
        "$$\n",
        "L = -\\frac{1}{N} \\sum_{n=1}^N \\sum_{i=1}^C y_{ni} \\log(p_{ni})\n",
        "$$\n",
        "\n",
        "- \\(N\\): The number of samples.\n",
        "- \\(y_{ni}\\): The actual binary indicator for sample \\(n\\) and class \\(i\\).\n",
        "- \\(p_{ni}\\): The predicted probability for sample \\(n\\) and class \\(i\\)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define loss function\n",
        "criterion = nn.CrossEntropyLoss()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "For the following part:\n",
        "\n",
        "The **train_model** funtion trains a given model on the training dataset for a specified number of epochs while tracking the loss and accuracy.\n",
        "\n",
        "The **evaluate_model** functio evaluates the trained model on the test dataset.\n",
        "\n",
        "The **train_model_inception** function trains the InceptionV3 model with accuracy tracking. The function outputs a tuple when *aux_logits* is *True*. The code checks if the output is a tuple and uses only the main output (ignoring auxiliary outputs)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "mYq_yD2h2ZCa"
      },
      "outputs": [],
      "source": [
        "# Function to train the model with accuracy tracking\n",
        "def train_model(model, trainloader, criterion, optimizer, num_epochs=25):\n",
        "    model.train()\n",
        "    for epoch in range(num_epochs):\n",
        "        running_loss = 0.0\n",
        "        correct = 0\n",
        "        total = 0\n",
        "        start_time = time.time()\n",
        "        for i, data in enumerate(trainloader, 0):\n",
        "            inputs, labels = data[0].to(device), data[1].to(device)\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            running_loss += loss.item()\n",
        "\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "            correct += torch.sum(preds == labels).item()\n",
        "            total += labels.size(0)\n",
        "\n",
        "        epoch_loss = running_loss / len(trainloader)\n",
        "        epoch_accuracy = correct / total\n",
        "        end_time = time.time()\n",
        "\n",
        "        print(f\"Epoch {epoch+1}, Loss: {epoch_loss:.4f}, Accuracy: {epoch_accuracy:.4f}, Time: {end_time - start_time:.2f} seconds\")\n",
        "\n",
        "# Function to evaluate the model\n",
        "def evaluate_model(model, testloader):\n",
        "    model.eval()\n",
        "    all_preds = []\n",
        "    all_labels = []\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in testloader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            outputs = model(inputs)\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "            correct += torch.sum(preds == labels).item()\n",
        "            total += labels.size(0)\n",
        "            all_preds.extend(preds.cpu().numpy())\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "    accuracy = correct / total\n",
        "    f1 = f1_score(all_labels, all_preds, average='weighted')\n",
        "    return accuracy, f1\n",
        "\n",
        "# Define a modified train function for InceptionV3\n",
        "def train_model_inception(model, trainloader, criterion, optimizer, num_epochs=25):\n",
        "    model.train()\n",
        "    for epoch in range(num_epochs):\n",
        "        running_loss = 0.0\n",
        "        start_time = time.time()\n",
        "        correct = 0\n",
        "        total = 0\n",
        "        for i, data in enumerate(trainloader, 0):\n",
        "            inputs, labels = data[0].to(device), data[1].to(device)\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(inputs)\n",
        "            if isinstance(outputs, tuple):\n",
        "                outputs = outputs[0]  # Use only the main output\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            running_loss += loss.item()\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "            correct += (preds == labels).sum().item()\n",
        "            total += labels.size(0)\n",
        "        end_time = time.time()\n",
        "        epoch_accuracy = correct / total\n",
        "        print(f\"Epoch {epoch+1}, Loss: {running_loss / len(trainloader)}, Accuracy: {epoch_accuracy * 100:.2f}%, Time: {end_time - start_time} seconds\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### **Model's training**\n",
        "\n",
        "Now, each one of the architectures previously mentioned are trained in the same way. The models are trained in the training data for 25 epochs using the Adam optimizer with a learning rate of 0.001. The most important definition of this section are the following:\n",
        "\n",
        "- **Epoch** refers to one complete pass of the entire training dataset through the learning algorithm. \n",
        "\n",
        "- **Adam optimizer** (*optim.Adam*) is an adaptive learning rate optimization algorithm designed specifically for training deep neural networks. It combines the advantages of two other extensions of stochastic gradient descent: AdaGrad and RMSProp.\n",
        "\n",
        "- **Learning rate** controls how much to change the model in response to the estimated error each time the model weights are updated during training. \n",
        "\n",
        "After training, the model is evaluated on the test data (testloader) to calculate the accuracy and F1 score. Finally, the results including the accuracy, F1 score, and training time are printed to the console."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### **AlexNet**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BvVVRhzZ5jC8",
        "outputId": "ffcbb461-5a89-44b9-a99f-9b0eb1c465f5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Training AlexNet...\n",
            "\n",
            "Epoch 1, Loss: 4.6260, Accuracy: 0.0078, Time: 7.30 seconds\n",
            "Epoch 2, Loss: 4.6256, Accuracy: 0.0098, Time: 7.20 seconds\n",
            "Epoch 3, Loss: 4.6260, Accuracy: 0.0039, Time: 7.44 seconds\n",
            "Epoch 4, Loss: 4.6263, Accuracy: 0.0078, Time: 7.32 seconds\n",
            "Epoch 5, Loss: 4.6268, Accuracy: 0.0049, Time: 7.20 seconds\n",
            "Epoch 6, Loss: 4.6280, Accuracy: 0.0029, Time: 7.22 seconds\n",
            "Epoch 7, Loss: 4.6286, Accuracy: 0.0059, Time: 7.33 seconds\n",
            "Epoch 8, Loss: 4.6294, Accuracy: 0.0029, Time: 7.19 seconds\n",
            "Epoch 9, Loss: 4.6294, Accuracy: 0.0039, Time: 7.46 seconds\n",
            "Epoch 10, Loss: 4.6294, Accuracy: 0.0098, Time: 7.38 seconds\n",
            "Epoch 11, Loss: 4.6274, Accuracy: 0.0029, Time: 7.05 seconds\n",
            "Epoch 12, Loss: 4.6260, Accuracy: 0.0059, Time: 7.43 seconds\n",
            "Epoch 13, Loss: 4.6256, Accuracy: 0.0069, Time: 7.24 seconds\n",
            "Epoch 14, Loss: 4.6259, Accuracy: 0.0069, Time: 7.25 seconds\n",
            "Epoch 15, Loss: 4.6255, Accuracy: 0.0039, Time: 7.25 seconds\n",
            "Epoch 16, Loss: 4.6258, Accuracy: 0.0039, Time: 7.40 seconds\n",
            "Epoch 17, Loss: 4.6255, Accuracy: 0.0078, Time: 7.33 seconds\n",
            "Epoch 18, Loss: 4.6256, Accuracy: 0.0088, Time: 7.43 seconds\n",
            "Epoch 19, Loss: 4.6257, Accuracy: 0.0098, Time: 7.23 seconds\n",
            "Epoch 20, Loss: 4.6258, Accuracy: 0.0088, Time: 7.20 seconds\n",
            "Epoch 21, Loss: 4.6257, Accuracy: 0.0078, Time: 7.46 seconds\n",
            "Epoch 22, Loss: 4.6256, Accuracy: 0.0088, Time: 7.23 seconds\n",
            "Epoch 23, Loss: 4.6256, Accuracy: 0.0059, Time: 7.06 seconds\n",
            "Epoch 24, Loss: 4.6256, Accuracy: 0.0059, Time: 7.25 seconds\n",
            "Epoch 25, Loss: 4.6256, Accuracy: 0.0098, Time: 7.34 seconds\n",
            "AlexNet - Top-1 Accuracy: 0.94%\n",
            "AlexNet - F1 Score: 0.02%\n",
            "AlexNet - Training Time: 182.20 seconds\n"
          ]
        }
      ],
      "source": [
        "# Train and evaluate AlexNet\n",
        "model_name = 'AlexNet'\n",
        "print(f\"\\nTraining {model_name}...\\n\")\n",
        "model = models[model_name]\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001) # lr=0.001 is considered standar for the learning rate\n",
        "start_time = time.time()\n",
        "train_model(model, trainloader, criterion, optimizer, num_epochs=25) # num_epochs=25 due to hardware limitation\n",
        "training_time = time.time() - start_time\n",
        "accuracy, f1 = evaluate_model(model, testloader)\n",
        "\n",
        "print(f\"{model_name} - Top-1 Accuracy: {accuracy * 100:.2f}%\")\n",
        "print(f\"{model_name} - F1 Score: {f1 * 100:.2f}%\")\n",
        "print(f\"{model_name} - Training Time: {training_time:.2f} seconds\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### **ResNet-50**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mfnZpVcf2d5o",
        "outputId": "4a335ff2-d3ac-4375-8aa3-0795908dadf4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Training ResNet50...\n",
            "\n",
            "Epoch 1, Loss: 4.7556, Accuracy: 0.0402, Time: 101.96 seconds\n",
            "Epoch 2, Loss: 4.3269, Accuracy: 0.0412, Time: 123.19 seconds\n",
            "Epoch 3, Loss: 3.8430, Accuracy: 0.0686, Time: 107.46 seconds\n",
            "Epoch 4, Loss: 3.3960, Accuracy: 0.1343, Time: 103.04 seconds\n",
            "Epoch 5, Loss: 2.9675, Accuracy: 0.2206, Time: 100.98 seconds\n",
            "Epoch 6, Loss: 2.4951, Accuracy: 0.3265, Time: 101.05 seconds\n",
            "Epoch 7, Loss: 2.2786, Accuracy: 0.3775, Time: 100.56 seconds\n",
            "Epoch 8, Loss: 1.7822, Accuracy: 0.5010, Time: 100.43 seconds\n",
            "Epoch 9, Loss: 1.4218, Accuracy: 0.5892, Time: 99.40 seconds\n",
            "Epoch 10, Loss: 1.2098, Accuracy: 0.6520, Time: 96.95 seconds\n",
            "Epoch 11, Loss: 0.8811, Accuracy: 0.7451, Time: 98.46 seconds\n",
            "Epoch 12, Loss: 0.7757, Accuracy: 0.7676, Time: 100.59 seconds\n",
            "Epoch 13, Loss: 0.5511, Accuracy: 0.8431, Time: 100.34 seconds\n",
            "Epoch 14, Loss: 0.3540, Accuracy: 0.9029, Time: 100.73 seconds\n",
            "Epoch 15, Loss: 0.2226, Accuracy: 0.9471, Time: 100.80 seconds\n",
            "Epoch 16, Loss: 0.1868, Accuracy: 0.9461, Time: 100.02 seconds\n",
            "Epoch 17, Loss: 0.1307, Accuracy: 0.9686, Time: 100.66 seconds\n",
            "Epoch 18, Loss: 0.1370, Accuracy: 0.9647, Time: 100.77 seconds\n",
            "Epoch 19, Loss: 0.2001, Accuracy: 0.9471, Time: 100.58 seconds\n",
            "Epoch 20, Loss: 0.2043, Accuracy: 0.9422, Time: 100.59 seconds\n",
            "Epoch 21, Loss: 0.2029, Accuracy: 0.9343, Time: 100.16 seconds\n",
            "Epoch 22, Loss: 0.1429, Accuracy: 0.9598, Time: 99.77 seconds\n",
            "Epoch 23, Loss: 0.0988, Accuracy: 0.9784, Time: 100.56 seconds\n",
            "Epoch 24, Loss: 0.1490, Accuracy: 0.9598, Time: 100.25 seconds\n",
            "Epoch 25, Loss: 0.1102, Accuracy: 0.9745, Time: 99.92 seconds\n",
            "ResNet50 - Top-1 Accuracy: 48.51%\n",
            "ResNet50 - F1 Score: 49.03%\n",
            "ResNet50 - Training Time: 2539.22 seconds\n"
          ]
        }
      ],
      "source": [
        "# Train and evaluate ResNet50\n",
        "model_name = 'ResNet50'\n",
        "print(f\"\\nTraining {model_name}...\\n\")\n",
        "model = models[model_name]\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "start_time = time.time()\n",
        "train_model(model, trainloader, criterion, optimizer, num_epochs=25)\n",
        "training_time = time.time() - start_time\n",
        "accuracy, f1 = evaluate_model(model, testloader)\n",
        "\n",
        "print(f\"{model_name} - Top-1 Accuracy: {accuracy * 100:.2f}%\")\n",
        "print(f\"{model_name} - F1 Score: {f1 * 100:.2f}%\")\n",
        "print(f\"{model_name} - Training Time: {training_time:.2f} seconds\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### **VGG-16**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3oZfYjdj5sNf",
        "outputId": "eb5e5f80-a2a2-40f1-b0f6-018e69ad97f5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Training VGG16...\n",
            "\n",
            "Epoch 1, Loss: 4.7589, Accuracy: 0.0078, Time: 475.20 seconds\n",
            "Epoch 2, Loss: 4.6422, Accuracy: 0.0059, Time: 468.42 seconds\n",
            "Epoch 3, Loss: 4.6482, Accuracy: 0.0059, Time: 472.10 seconds\n",
            "Epoch 4, Loss: 4.6386, Accuracy: 0.0069, Time: 477.71 seconds\n",
            "Epoch 5, Loss: 4.6544, Accuracy: 0.0039, Time: 455.08 seconds\n",
            "Epoch 6, Loss: 4.6652, Accuracy: 0.0137, Time: 452.59 seconds\n",
            "Epoch 7, Loss: 4.6341, Accuracy: 0.0069, Time: 456.47 seconds\n",
            "Epoch 8, Loss: 4.6268, Accuracy: 0.0127, Time: 451.33 seconds\n",
            "Epoch 9, Loss: 4.6080, Accuracy: 0.0108, Time: 450.89 seconds\n",
            "Epoch 10, Loss: 4.5824, Accuracy: 0.0069, Time: 451.50 seconds\n",
            "Epoch 11, Loss: 4.4838, Accuracy: 0.0186, Time: 451.21 seconds\n",
            "Epoch 12, Loss: 4.4472, Accuracy: 0.0108, Time: 451.30 seconds\n",
            "Epoch 13, Loss: 4.3860, Accuracy: 0.0147, Time: 450.57 seconds\n",
            "Epoch 14, Loss: 4.3273, Accuracy: 0.0225, Time: 452.21 seconds\n",
            "Epoch 15, Loss: 4.4369, Accuracy: 0.0265, Time: 451.05 seconds\n",
            "Epoch 16, Loss: 4.2231, Accuracy: 0.0353, Time: 451.30 seconds\n",
            "Epoch 17, Loss: 4.1619, Accuracy: 0.0343, Time: 450.86 seconds\n",
            "Epoch 18, Loss: 4.1130, Accuracy: 0.0480, Time: 451.21 seconds\n",
            "Epoch 19, Loss: 4.0309, Accuracy: 0.0480, Time: 451.75 seconds\n",
            "Epoch 20, Loss: 4.0272, Accuracy: 0.0539, Time: 450.78 seconds\n",
            "Epoch 21, Loss: 3.8747, Accuracy: 0.0706, Time: 450.68 seconds\n",
            "Epoch 22, Loss: 3.8198, Accuracy: 0.0833, Time: 451.96 seconds\n",
            "Epoch 23, Loss: 3.6844, Accuracy: 0.0853, Time: 451.73 seconds\n",
            "Epoch 24, Loss: 3.5580, Accuracy: 0.1235, Time: 451.36 seconds\n",
            "Epoch 25, Loss: 3.4651, Accuracy: 0.1471, Time: 451.29 seconds\n",
            "VGG16 - Top-1 Accuracy: 6.07%\n",
            "VGG16 - F1 Score: 0.03\n",
            "VGG16 - Training Time: 11380.55 seconds\n"
          ]
        }
      ],
      "source": [
        "# Train and evaluate VGG16\n",
        "model_name = 'VGG16'\n",
        "print(f\"\\nTraining {model_name}...\\n\")\n",
        "model = models[model_name]\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "start_time = time.time()\n",
        "train_model(model, trainloader, criterion, optimizer, num_epochs=25)\n",
        "training_time = time.time() - start_time\n",
        "accuracy, f1 = evaluate_model(model, testloader)\n",
        "\n",
        "print(f\"{model_name} - Top-1 Accuracy: {accuracy * 100:.2f}%\")\n",
        "print(f\"{model_name} - F1 Score: {f1:.2f}\")\n",
        "print(f\"{model_name} - Training Time: {training_time:.2f} seconds\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### **GoogleNet: Inception V3**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0CdsQ_ie5vbj",
        "outputId": "123992f0-275f-4873-c7b4-b974dc76d8aa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Training InceptionV3...\n",
            "\n",
            "Epoch 1, Loss: 4.403911046683788, Accuracy: 8.04%, Time: 361.23323249816895 seconds\n",
            "Epoch 2, Loss: 2.977291002869606, Accuracy: 28.53%, Time: 341.2345886230469 seconds\n",
            "Epoch 3, Loss: 2.0481783524155617, Accuracy: 46.18%, Time: 336.2950701713562 seconds\n",
            "Epoch 4, Loss: 1.4312483929097652, Accuracy: 60.39%, Time: 330.7246196269989 seconds\n",
            "Epoch 5, Loss: 0.9784657210111618, Accuracy: 72.55%, Time: 330.96296668052673 seconds\n",
            "Epoch 6, Loss: 0.6254676431417465, Accuracy: 82.75%, Time: 331.0347945690155 seconds\n",
            "Epoch 7, Loss: 0.49142562272027135, Accuracy: 86.67%, Time: 330.55593848228455 seconds\n",
            "Epoch 8, Loss: 0.41412029042840004, Accuracy: 88.92%, Time: 338.07885217666626 seconds\n",
            "Epoch 9, Loss: 0.2777302369941026, Accuracy: 92.94%, Time: 342.7504951953888 seconds\n",
            "Epoch 10, Loss: 0.21562380297109485, Accuracy: 94.80%, Time: 343.76017332077026 seconds\n",
            "Epoch 11, Loss: 0.11300348734948784, Accuracy: 97.45%, Time: 333.3437535762787 seconds\n",
            "Epoch 12, Loss: 0.13541262823855504, Accuracy: 96.76%, Time: 331.0965619087219 seconds\n",
            "Epoch 13, Loss: 0.1318694690708071, Accuracy: 97.16%, Time: 338.8518946170807 seconds\n",
            "Epoch 14, Loss: 0.11593206803081557, Accuracy: 96.96%, Time: 337.91484928131104 seconds\n",
            "Epoch 15, Loss: 0.18657386349514127, Accuracy: 95.20%, Time: 340.06829953193665 seconds\n",
            "Epoch 16, Loss: 0.28309388225898147, Accuracy: 92.55%, Time: 334.6020300388336 seconds\n",
            "Epoch 17, Loss: 0.24386285711079836, Accuracy: 93.82%, Time: 328.46585512161255 seconds\n",
            "Epoch 18, Loss: 0.24390820297412574, Accuracy: 93.04%, Time: 328.14480996131897 seconds\n",
            "Epoch 19, Loss: 0.1680052820011042, Accuracy: 95.29%, Time: 328.50161576271057 seconds\n",
            "Epoch 20, Loss: 0.10745539970230311, Accuracy: 96.96%, Time: 328.85463666915894 seconds\n",
            "Epoch 21, Loss: 0.12444351601880044, Accuracy: 96.96%, Time: 328.62098932266235 seconds\n",
            "Epoch 22, Loss: 0.08394771671737544, Accuracy: 98.14%, Time: 328.1684546470642 seconds\n",
            "Epoch 23, Loss: 0.0972326222108677, Accuracy: 98.24%, Time: 328.2066185474396 seconds\n",
            "Epoch 24, Loss: 0.04967631273029838, Accuracy: 98.73%, Time: 328.5896530151367 seconds\n",
            "Epoch 25, Loss: 0.08816704381024465, Accuracy: 97.75%, Time: 328.566694021225 seconds\n",
            "InceptionV3 - Top-1 Accuracy: 62.30%\n",
            "InceptionV3 - F1 Score: 0.62\n",
            "Training and evaluation time for InceptionV3: 8358.65528011322 seconds\n"
          ]
        }
      ],
      "source": [
        "# Training and evaluating InceptionV3\n",
        "print(\"\\nTraining InceptionV3...\\n\")\n",
        "model_inceptionv3 = models['InceptionV3']\n",
        "optimizer_inceptionv3 = optim.Adam(model_inceptionv3.parameters(), lr=0.001)\n",
        "\n",
        "start_time = time.time()\n",
        "train_model_inception(model_inceptionv3, trainloader_inception, criterion, optimizer_inceptionv3, num_epochs=25)\n",
        "end_time = time.time()\n",
        "\n",
        "accuracy_inceptionv3, f1_inceptionv3 = evaluate_model(model_inceptionv3, testloader_inception)\n",
        "print(f\"InceptionV3 - Top-1 Accuracy: {accuracy_inceptionv3 * 100:.2f}%\")\n",
        "print(f\"InceptionV3 - F1 Score: {f1_inceptionv3:.2f}\")\n",
        "print(f\"Training and evaluation time for InceptionV3: {end_time - start_time} seconds\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### **EfficientNet-B1**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UQ029lrz5yeF",
        "outputId": "db055e97-bb9f-4501-e7e3-b779c9da15d5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Training EfficientNet-B1...\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1, Loss: 3.8232, Accuracy: 0.2667, Time: 101.96 seconds\n",
            "Epoch 2, Loss: 1.0012, Accuracy: 0.8461, Time: 105.30 seconds\n",
            "Epoch 3, Loss: 0.1939, Accuracy: 0.9794, Time: 99.56 seconds\n",
            "Epoch 4, Loss: 0.0697, Accuracy: 0.9941, Time: 99.25 seconds\n",
            "Epoch 5, Loss: 0.0313, Accuracy: 0.9990, Time: 99.25 seconds\n",
            "Epoch 6, Loss: 0.0167, Accuracy: 1.0000, Time: 99.56 seconds\n",
            "Epoch 7, Loss: 0.0115, Accuracy: 1.0000, Time: 99.24 seconds\n",
            "Epoch 8, Loss: 0.0070, Accuracy: 1.0000, Time: 99.53 seconds\n",
            "Epoch 9, Loss: 0.0060, Accuracy: 1.0000, Time: 99.43 seconds\n",
            "Epoch 10, Loss: 0.0043, Accuracy: 1.0000, Time: 99.32 seconds\n",
            "Epoch 11, Loss: 0.0037, Accuracy: 1.0000, Time: 99.74 seconds\n",
            "Epoch 12, Loss: 0.0027, Accuracy: 1.0000, Time: 99.58 seconds\n",
            "Epoch 13, Loss: 0.0027, Accuracy: 1.0000, Time: 99.29 seconds\n",
            "Epoch 14, Loss: 0.0021, Accuracy: 1.0000, Time: 99.29 seconds\n",
            "Epoch 15, Loss: 0.0021, Accuracy: 1.0000, Time: 99.32 seconds\n",
            "Epoch 16, Loss: 0.0022, Accuracy: 1.0000, Time: 98.78 seconds\n",
            "Epoch 17, Loss: 0.0018, Accuracy: 1.0000, Time: 99.46 seconds\n",
            "Epoch 18, Loss: 0.0020, Accuracy: 1.0000, Time: 99.48 seconds\n",
            "Epoch 19, Loss: 0.0039, Accuracy: 0.9990, Time: 99.23 seconds\n",
            "Epoch 20, Loss: 0.0741, Accuracy: 0.9882, Time: 99.55 seconds\n",
            "Epoch 21, Loss: 0.3074, Accuracy: 0.9216, Time: 99.11 seconds\n",
            "Epoch 22, Loss: 0.7385, Accuracy: 0.8147, Time: 100.14 seconds\n",
            "Epoch 23, Loss: 0.6404, Accuracy: 0.8284, Time: 100.39 seconds\n",
            "Epoch 24, Loss: 0.3072, Accuracy: 0.9196, Time: 99.14 seconds\n",
            "Epoch 25, Loss: 0.1252, Accuracy: 0.9696, Time: 99.50 seconds\n",
            "EfficientNet-B1 - Top-1 Accuracy: 80.66%\n",
            "EfficientNet-B1 - F1 Score: 0.81\n",
            "EfficientNet-B1 - Training Time: 2494.40 seconds\n"
          ]
        }
      ],
      "source": [
        "# Training and evaluating EfficientNet-B1\n",
        "print(\"\\nTraining EfficientNet-B1...\\n\")\n",
        "model_efficientnet_b1 = models['EfficientNet-B1'].to(device)  # Ensure the model is on GPU\n",
        "optimizer_efficientnet_b1 = optim.Adam(model_efficientnet_b1.parameters(), lr=0.001)\n",
        "\n",
        "start_time = time.time()\n",
        "train_model(model_efficientnet_b1, trainloader, criterion, optimizer_efficientnet_b1, num_epochs=25)\n",
        "training_time = time.time() - start_time\n",
        "\n",
        "accuracy_efficientnet_b1, f1_efficientnet_b1 = evaluate_model(model_efficientnet_b1, testloader)\n",
        "print(f\"EfficientNet-B1 - Top-1 Accuracy: {accuracy_efficientnet_b1 * 100:.2f}%\")\n",
        "print(f\"EfficientNet-B1 - F1 Score: {f1_efficientnet_b1:.2f}\")\n",
        "print(f\"EfficientNet-B1 - Training Time: {training_time:.2f} seconds\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### **EfficientNet-B3**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P8W82ErW51hc",
        "outputId": "c24ffc42-313d-4418-e871-d975824f5ac9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Training EfficientNet-B3...\n",
            "\n",
            "Epoch 1, Loss: 3.8952, Accuracy: 0.2275, Time: 178.53 seconds\n",
            "Epoch 2, Loss: 1.3263, Accuracy: 0.7559, Time: 177.42 seconds\n",
            "Epoch 3, Loss: 0.3527, Accuracy: 0.9353, Time: 177.18 seconds\n",
            "Epoch 4, Loss: 0.1565, Accuracy: 0.9735, Time: 177.41 seconds\n",
            "Epoch 5, Loss: 0.1028, Accuracy: 0.9794, Time: 177.05 seconds\n",
            "Epoch 6, Loss: 0.0750, Accuracy: 0.9804, Time: 177.03 seconds\n",
            "Epoch 7, Loss: 0.0462, Accuracy: 0.9931, Time: 177.31 seconds\n",
            "Epoch 8, Loss: 0.0384, Accuracy: 0.9931, Time: 177.29 seconds\n",
            "Epoch 9, Loss: 0.0359, Accuracy: 0.9941, Time: 177.30 seconds\n",
            "Epoch 10, Loss: 0.0615, Accuracy: 0.9853, Time: 177.04 seconds\n",
            "Epoch 11, Loss: 0.0623, Accuracy: 0.9902, Time: 177.18 seconds\n",
            "Epoch 12, Loss: 0.0219, Accuracy: 0.9971, Time: 178.35 seconds\n",
            "Epoch 13, Loss: 0.0485, Accuracy: 0.9882, Time: 184.73 seconds\n",
            "Epoch 14, Loss: 0.0532, Accuracy: 0.9833, Time: 178.82 seconds\n",
            "Epoch 15, Loss: 0.0704, Accuracy: 0.9804, Time: 177.05 seconds\n",
            "Epoch 16, Loss: 0.0784, Accuracy: 0.9843, Time: 177.97 seconds\n",
            "Epoch 17, Loss: 0.1147, Accuracy: 0.9696, Time: 183.38 seconds\n",
            "Epoch 18, Loss: 0.1555, Accuracy: 0.9539, Time: 177.76 seconds\n",
            "Epoch 19, Loss: 0.1122, Accuracy: 0.9676, Time: 177.66 seconds\n",
            "Epoch 20, Loss: 0.0945, Accuracy: 0.9765, Time: 177.61 seconds\n",
            "Epoch 21, Loss: 0.0543, Accuracy: 0.9873, Time: 177.57 seconds\n",
            "Epoch 22, Loss: 0.0889, Accuracy: 0.9824, Time: 177.39 seconds\n",
            "Epoch 23, Loss: 0.0391, Accuracy: 0.9922, Time: 177.30 seconds\n",
            "Epoch 24, Loss: 0.0331, Accuracy: 0.9902, Time: 177.48 seconds\n",
            "Epoch 25, Loss: 0.0287, Accuracy: 0.9931, Time: 177.38 seconds\n",
            "EfficientNet-B3 - Top-1 Accuracy: 83.25%\n",
            "EfficientNet-B3 - F1 Score: 0.84\n",
            "EfficientNet-B3 - Training Time: 4451.19 seconds\n"
          ]
        }
      ],
      "source": [
        "# Training and evaluating EfficientNet-B3\n",
        "print(\"\\nTraining EfficientNet-B3...\\n\")\n",
        "model_efficientnet_b3 = models['EfficientNet-B3'].to(device)  # Ensure the model is on GPU\n",
        "optimizer_efficientnet_b3 = optim.Adam(model_efficientnet_b3.parameters(), lr=0.001)\n",
        "\n",
        "start_time = time.time()\n",
        "train_model(model_efficientnet_b3, trainloader, criterion, optimizer_efficientnet_b3, num_epochs=25)\n",
        "training_time = time.time() - start_time\n",
        "\n",
        "accuracy_efficientnet_b3, f1_efficientnet_b3 = evaluate_model(model_efficientnet_b3, testloader)\n",
        "print(f\"EfficientNet-B3 - Top-1 Accuracy: {accuracy_efficientnet_b3 * 100:.2f}%\")\n",
        "print(f\"EfficientNet-B3 - F1 Score: {f1_efficientnet_b3:.2f}\")\n",
        "print(f\"EfficientNet-B3 - Training Time: {training_time:.2f} seconds\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
